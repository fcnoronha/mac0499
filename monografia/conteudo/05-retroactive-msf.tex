%!TeX root=../monografia.tex

%% ------------------------------------------------------------------------- %%
\chapter{Floresta Geradora Mínima Semi-Retroativa}
\label{cap:retroactive-msf}

Neste capitulo, descreveremos uma versão aprimorada solução apresentada por \citet{10.1093/comjnl/bxaa135} para o problema da floresta geradora mínima retroativa --- \emph{retroactive minimum spanning forest}, em inglês. Esta versão utiliza a técnica de \emph{square-root decomposition} junto com a estrutura do Capítulo \ref{cap:incremental-msf} para solucionar o problema.

%% ------------------------------------------------------------------------- %%
\section{Nomenclatura}
\label{sec:nomeclatura}

Tendo em vista as definições acerca de estruturas de dados parcialmente e totalmente retroativas, mostradas no Capítulo \ref{cap:introducao}, decidimos nos referir tanto a solução de Andrade Júnior e Duarte Seabra quanto a versão aqui apresentada como \emph{semi-retroativas}. Isto se da pelo fato de ambas suportarem inserções e consultas em qualquer instante de tempo, porém nenhuma delas suporta a remoção de uma operação, o que as exclui de qualquer uma das duas definições.

Vale notar que \citet{DBLP:journals/corr/abs-1910-03332} apresentam ainda outra definição, a de \emph{estrutura de dados incremental totalmente retroativa}. Neste contexto, uma operação retroativa pode criar ou cancelar uma inserção, fazendo com que, no segundo caso, a operação cancelada seja totalmente removida da estrutura de dados. Entretanto, não se pode criar uma remoção, isto é, não existe suporte para que uma operação seja cancelada somente após um certo instante de tempo. Portanto, apesar de um nome sugestivo, essa definição também não contempla a solução que vamos estudar neste capítulo.

%% ------------------------------------------------------------------------- %%
\section{Square-root decomposition}
\label{sec:sqrt-decomp}

Inicialmente, vamos conhecer a técnica de \emph{square-root decomposition}, utilizada para transformar soluções que consomem tempo $\Oh(\log n)$ --- onde $n$ é o número de elementos no problema em questão --- em soluções com custo $\Oh(\sqrt{n})$. Para nossa explicação, vamos utilizar o seguinte problema como exemplo: dado uma lista de inteiros $ [ a_1, a_2, a_3, \dots, a_n ] $, queremos conseguir efetuar as duas operações a seguir:

\begin{itemize}
    \item \texttt{find\_sum(l, r)}: determina a soma de todos os valores no intervalo $[l,r]$;
    \item \texttt{update\_value(i, x)}: atualiza para $x$ o valor do elemento na posição $i$.
\end{itemize}

Este problema possui duas soluções \emph{ingênuas}, cada uma favorecendo uma das operações. A primeira, e mais simples, consiste em utilizar um \emph{loop} para responder consultas \texttt{find\_sum}, o que acaba custando $\Oh(n)$, e apenas atualizando a respectiva posição para a operação \texttt{update\_value}, o que consome tempo $\Oh(1)$.

Já a segunda solução se resume a utilizarmos um vetor de soma de prefixos --- isto é, um vetor tal que \texttt{prefix\_sum[i]} equivale a $\Sigma_{j=1}^{i} a_j$ --- para respondermos as consultas \texttt{find\_sum} em tempo constante, porém, acarretando na reconstrução de \texttt{prefix\_sum} em toda chamada de \texttt{update\_value}, o que consome $\Oh(n)$.

Todavia, utilizando a \emph{square-root decomposition}, podemos responder consultas do primeiro tipo em tempo $\Oh(\sqrt{n})$ e executa rotinas do segundo tipo em tempo constante, um bom meio termo. O cerne desta técnica consiste em duas etapas. Primeiramente, dividimos a estrutura de interesse --- neste caso, a lista de inteiros --- em $d$ blocos de tamanho $b$. Sem perda de generalidade, assumimos que $n$, o tamanho da lista, é um múltiplo de $b$, com $d = \frac{n}{b}$. Em seguida, para cada um dos blocos, pré-calculamos alguma informação auxiliar. No problema utilizado como exemplo, isso se traduz em pré-calcular a soma de todos os elementos dentro de um bloco.

Com isso, podemos explicar como adaptamos as operações para funcionarem utilizando esta divisão em blocos. Apesar de estarmos focados em resolver o problema de soma em um intervalo, a \emph{receita} por trás dessa adaptação pode ser facilmente utilizada em outros contextos, como veremos na próxima seção.

Para respondermos consultas do tipo \texttt{find\_sum(l, r)}, utilizaremos o pré-cálculo realizado nos blocos para eliminar a necessidade de percorrer todos os elementos no intervalo entre $l$ e $r$. Primeiramente, iteramos sob todos os blocos completamente contidos no intervalo e acumulamos a respectiva soma em uma variável $y$. Com isso em mãos, podemos nos concentrar para calcular a soma $x$ e $z$ das \emph{pontas} do intervalo, isto é, os pedaços que fazem parte de um bloco não totalmente contido no intervalo, utilizando um simples \emph{loop}. Esta tarefa está representada na Figura \ref{fig:sqrt-decomp-blocks} e podemos perceber que a reposta para a consulta é simplesmente a soma $x + y + z$.

\begin{figure}
    \centering
    \begin{equation*}
        \underbracket{a_1, a_2, \overbrace{a_3, a_4}^x}_{block_1} \quad
        \overbrace{
            \underbracket{a_5, a_6, a_7, a_8}_{block_2} \quad
            \dots \quad
            \underbracket{a_{n-7}, a_{n-6}, a_{n-5}, a_{n-4}}_{block_{d-1}}
        }^y \quad
        \underbracket{\overbrace{a_{n-3}, a_{n-2}, a_{n-1}}^z, a_n}_{block_d}
    \end{equation*}
    \caption{Divisão de uma lista de tamanho $n$ em $d$ blocos de tamanho $b$, mostrando que a soma de $x$, $y$ e $z$ responde a consulta feita por \texttt{find\_sum(3, n-1)}.}
    \label{fig:sqrt-decomp-blocks}
\end{figure}

Já a rotina \texttt{update\_value(i, x)} é um pouco mais simples. Ao atualizamos o valor da posição $i$, temos simplesmente que atualizar o valor pré-calculado do bloco que o contém, e isso é o suficiente.

Note que a segunda operação tem um custo constante, dado que apenas atualizamos um único valor, porém a primeira operação requer uma análise mais cuidadosa. Para encontrar os valores das \emph{pontas}, $x$ e $z$, somos obrigados a realizar um \emph{loop} sob estes elementos, e como no pior caso podemos acabar percorrendo $b-1$ elementos, esta etapa tem custo $\Oh(b)$. Já para encontrar $y$, iteramos sob os blocos em si, portanto, no pior caso, gastamos $\Oh(d)$ para o seu cálculo. Com isso, temos que a consulta \texttt{find\_sum} tem um custo final $\Oh(\max(b, d))$.

Com o intuito de maximizarmos a eficiência desta função, queremos encontrar um tamanho de bloco $b$ ótimo que minimize o valor de $\max(b, d)$, isto é, que tornem $b$ e $d$ os mais próximos possível. Para isso, podemos fazer:

\begin{equation}
    b = d \Rightarrow
    b = \frac{n}{b} \Rightarrow
    b^2 = n \Rightarrow
    b = \pm \sqrt{n}
\end{equation}

Portanto, $\sqrt{n}$ é o tamanho ótimo para um bloco, o que implica que a nossa lista será dividida em $\sqrt{n}$ blocos, daí o nome da técnica. Finalmente, temos agora que a consulta \texttt{find\_sum} consome tempo $\Oh(\sqrt{n})$.

%% ------------------------------------------------------------------------- %%
\section{Rotinas extras para a versão incremental}
\label{sec:imsf-extras}

Antes de seguirmos adiante com a explicação versão do problema, temos que apresentar duas funções extras adicionadas na nossa solução para a versão incremental do problema. Em particular, ambas possuem o mesmo objetivo: possibilitar consultas acerca da floresta maximal de peso mínimo após a adição de um conjunto de arestas sem que tais modificações persistam na estrutura original. Em outras palavras, elas simulam o que poderia ser consultado caso fizéssemos estas adições de arestas em uma cópia da estrutura, porém, sem o custo adicional que tal cópia implica.

Essas rotinas são as \texttt{get\_msf\_after\_operations(edges[])} e \texttt{get\_msf\_weight\_after\_operations(edges[])}, que recebem uma lista de arestas e retornam, respectivamente, as arestas que fazem parte de uma floresta maximal de peso mínimo e seu peso caso as arestas da lista fornecida fossem adicionas ao grafo. Desta forma, a execução destes métodos consiste em três etapas: adição das arestas na estrutura; realização da consulta que estamos interessados; reversão da estrutura para o seu estado inicial.

Para a realização da primeira etapa, criamos o método \texttt{apply\_add\_edge\_operations}, que recebe uma lista de arestas, e realiza a adição delas na estrutura, de maneira muito similar ao que acontece na rotina \texttt{add\_edge}. Entretanto, este método retorna uma lista de pares \texttt{\{operação, aresta\}}, indicando quais operações foram realizadas na \emph{link-cut tree} --- \texttt{link} ou \texttt{cut} --- assim como as arestas envolvidas em cada uma delas. Como este método é muito semelhante à rotina \texttt{add\_edge}, não mostraremos seu pseudo-código.

Logo, após realizarmos as consultas que estamos interessados, precisamos reverter as operações realizadas na \emph{link-cut tree}. Para isso, criamos o método \texttt{apply\_rollback}, que recebe a lista criada pela rotina acima e desfaz as operações. Note que, para mantermos a consistência da \emph{link-cut tree} durante este processo, precisamos percorrer esta lista de trás para frente, revertendo uma operação de cada vez.

\begin{algorithm}[h!]
    \caption{Rotina Apply Rollback}\label{imsf-apply-rollback}
    \begin{algorithmic}[1]
        \Function{apply\_rollback}{\emph{operations\_list[]}}
        \State \emph{revert(operations\_list)}
        \ForEach{\emph{(operation, edge) in operations\_list}}
        \If{\emph{operation = link}}
        \State \emph{linkCutTree.cut(edge.u, edge.v)}
        \State \emph{current\_msf.erase(edge.id)}
        \State \emph{current\_msf\_weight -= edge.w}
        \Else
        \State \emph{linkCutTree.link(edge.u, edge.v, edge.w, edge.id)}
        \State \emph{current\_msf.append(edge.id)}
        \State \emph{current\_msf\_weight += edge.w}
        \EndIf
        \EndFor
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Finalmente, com estes métodos em mãos, podemos implementar as rotinas extras que estávamos interessados. Vamos mostrar somente o pseudo-código da rotina \texttt{get\_msf\_after\_operations}, dado que a única diferença entre as duas implementações seria a chamada na terceira linha.

\begin{algorithm}[h!]
    \caption{Rotina Get MSF After Operations}\label{imsf-msf-after}
    \begin{algorithmic}[1]
        \Function{get\_msf\_after\_operations}{\emph{edges[]}}
        \State \emph{rollback\_operations $\gets$ apply\_add\_edge\_operations(edges)}
        \State \emph{msf $\gets$ get\_msf()}
        \State \emph{apply\_rollback(rollback\_operations)}
        \State \Return \emph{msf}
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Além disso, podemos perceber que a complexidade destes métodos é proporcional à $\Oh(q \log m)$, onde $q$ é o número de arestas na lista \texttt{edges[]}.

%% ------------------------------------------------------------------------- %%
\section{Ideia}
\label{sec:rmsf-ideia}

% \todo{mostrar ideia, falar que a implimentaçao que vamos mostrar tem uma limitacao, por isso chamamos ela de semi retroativa}
% \todo{falar floresta geradora maximal de peso minima}
% \todo{mostrar implementação de 1 ou 2 métodos internos}

Agora, com todas as peças necessárias em mãos, podemos partir para a explicação da solução. Assim como no Capítulo \ref{cap:incremental-msf}, estamos interessados em resolver o \emph{problema da floresta geradora maximal de peso mínimo}, porem agora em sua versão semi-retroativa.

Em particular, queremos ser capazes de adicionar uma aresta ao grafo em certo estante de tempo, assim como realizar consultas acerca da floresta geradora maximal de peso mínimo em algum momento do presente ou do passado. Para isso, a estrutura deve conseguir dar suporte a seguinte interface:

\begin{itemize}
    \item \texttt{add\_edge(u, v, w, t)}: adiciona no grafo a aresta com pontas em $u$ e $v$ com peso $w$ no instante $t$;
    \item \texttt{get\_msf(t)}: retorna a lista com todas as arestas que compõem uma floresta maximal de peso mínimo do grafo no instante $t$;
    \item \texttt{get\_msf\_weight(t)}: retorna o custo de uma floresta maximal de peso mínimo do grafo no instante $t$.
\end{itemize}

Por último, a versão final apresentada faz com que estes três métodos tenham custo amortizado $\Oh(\sqrt m \log n)$, onde $m$ é o número de operações realizadas e $n$ é o número de vértices do grafo.

%% ------------------------------------------------------------------------- %%
\section{Versão original}
\label{sec:rmsf-versao-ori}

%% ------------------------------------------------------------------------- %%
\section{Versão melhorada}
\label{sec:rmsf-versao-mel}


%% ------------------------------------------------------------------------- %%
\section{Consultas Get MSF e Get MST Weight}
\label{sec:rmsf-get-msf}



%% ------------------------------------------------------------------------- %%
\section{Rotina Add Edge}
\label{sec:rmsf-add-edge}



%% ------------------------------------------------------------------------- %%
\section{Complexidade}
\label{sec:rmsf-complexidade}

\todo{falar da alternativa usada no paper do andre para contornar o problema da complexidade}
\todo{falar que poderiamos adaptar essa solucao usando link-cut trees persistentes, citar paper que a Cris mandou}
\todo{falar da complexidade da nossa variante da solucao proposta por Demaine}