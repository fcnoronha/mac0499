%!TeX root=../monografia.tex

%% ------------------------------------------------------------------------- %%
\chapter{Floresta Geradora Mínima Semi-Retroativa}
\label{cap:retroactive-msf}

Neste capitulo, descreveremos uma versão aprimorada solução apresentada por \citet{10.1093/comjnl/bxaa135} para o problema da floresta geradora mínima retroativa --- \emph{retroactive minimum spanning forest}, em inglês. Esta versão utiliza a técnica de \emph{square-root decomposition} junto com a estrutura do Capítulo \ref{cap:incremental-msf} para solucionar o problema.

%% ------------------------------------------------------------------------- %%
\section{Nomenclatura}
\label{sec:nomeclatura}

Tendo em vista as definições acerca de estruturas de dados parcialmente e totalmente retroativas, mostradas no Capítulo \ref{cap:introducao}, decidimos nos referir tanto a solução de Andrade Júnior e Duarte Seabra quanto a versão aqui apresentada como \emph{semi-retroativas}. Isto se da pelo fato de ambas suportarem inserções e consultas em qualquer instante de tempo, porém nenhuma delas suporta a remoção de uma operação, o que as exclui de qualquer uma das duas definições.

Vale notar que \citet{DBLP:journals/corr/abs-1910-03332} apresentam ainda outra definição, a de \emph{estrutura de dados incremental totalmente retroativa}. Neste contexto, uma operação retroativa pode criar ou cancelar uma inserção, fazendo com que, no segundo caso, a operação cancelada seja totalmente removida da estrutura de dados. Entretanto, não se pode criar uma remoção, isto é, não existe suporte para que uma operação seja cancelada somente após um certo instante de tempo. Portanto, apesar de um nome sugestivo, essa definição também não contempla a solução que vamos estudar neste capítulo.

%% ------------------------------------------------------------------------- %%
\section{Square-root decomposition}
\label{sec:sqrt-decomp}

Inicialmente, vamos conhecer a técnica de \emph{square-root decomposition}, utilizada para transformar soluções que consomem tempo $\Oh(\log n)$ --- onde $n$ é o número de elementos no problema em questão --- em soluções com custo $\Oh(\sqrt{n})$. Para nossa explicação, vamos utilizar o seguinte problema como exemplo: dado uma lista de inteiros $ [ a_1, a_2, a_3, \dots, a_n ] $, queremos conseguir efetuar as duas operações a seguir:

\begin{itemize}
    \item \texttt{find\_sum(l, r)}: determina a soma de todos os valores no intervalo $[l,r]$;
    \item \texttt{update\_value(i, x)}: atualiza para $x$ o valor do elemento na posição $i$.
\end{itemize}

Este problema possui duas soluções \emph{ingênuas}, cada uma favorecendo uma das operações. A primeira, e mais simples, consiste em utilizar um \emph{loop} para responder consultas \texttt{find\_sum}, o que acaba custando $\Oh(n)$, e apenas atualizando a respectiva posição para a operação \texttt{update\_value}, o que consome tempo $\Oh(1)$.

Já a segunda solução se resume a utilizarmos um vetor de soma de prefixos --- isto é, um vetor tal que \texttt{prefix\_sum[i]} equivale a $\Sigma_{j=1}^{i} a_j$ --- para respondermos as consultas \texttt{find\_sum} em tempo constante, porém, acarretando na reconstrução de \texttt{prefix\_sum} em toda chamada de \texttt{update\_value}, o que consome $\Oh(n)$.

Todavia, utilizando a \emph{square-root decomposition}, podemos responder consultas do primeiro tipo em tempo $\Oh(\sqrt{n})$ e executa rotinas do segundo tipo em tempo constante, um bom meio termo. O cerne desta técnica consiste em duas etapas. Primeiramente, dividimos a estrutura de interesse --- neste caso, a lista de inteiros --- em $d$ blocos de tamanho $b$. Sem perda de generalidade, assumimos que $n$, o tamanho da lista, é um múltiplo de $b$, com $d = \frac{n}{b}$. Em seguida, para cada um dos blocos, pré-calculamos alguma informação auxiliar. No problema utilizado como exemplo, isso se traduz em pré-calcular a soma de todos os elementos dentro de um bloco.

Com isso, podemos explicar como adaptamos as operações para funcionarem utilizando esta divisão em blocos. Apesar de estarmos focados em resolver o problema de soma em um intervalo, a \emph{receita} por trás dessa adaptação pode ser facilmente utilizada em outros contextos, como veremos na próxima seção.

Para respondermos consultas do tipo \texttt{find\_sum(l, r)}, utilizaremos o pré-cálculo realizado nos blocos para eliminar a necessidade de percorrer todos os elementos no intervalo entre $l$ e $r$. Primeiramente, iteramos sob todos os blocos completamente contidos no intervalo e acumulamos a respectiva soma em uma variável $y$. Com isso em mãos, podemos nos concentrar para calcular a soma $x$ e $z$ das \emph{pontas} do intervalo, isto é, os pedaços que fazem parte de um bloco não totalmente contido no intervalo, utilizando um simples \emph{loop}. Esta tarefa está representada na Figura \ref{fig:sqrt-decomp-blocks} e podemos perceber que a reposta para a consulta é simplesmente a soma $x + y + z$.

\begin{figure}
    \centering
    \begin{equation*}
        \underbracket{a_1, a_2, \overbrace{a_3, a_4}^x}_{block_1} \quad
        \overbrace{
            \underbracket{a_5, a_6, a_7, a_8}_{block_2} \quad
            \dots \quad
            \underbracket{a_{n-7}, a_{n-6}, a_{n-5}, a_{n-4}}_{block_{d-1}}
        }^y \quad
        \underbracket{\overbrace{a_{n-3}, a_{n-2}, a_{n-1}}^z, a_n}_{block_d}
    \end{equation*}
    \caption{Divisão de uma lista de tamanho $n$ em $d$ blocos de tamanho $b$, mostrando que a soma de $x$, $y$ e $z$ responde a consulta feita por \texttt{find\_sum(3, n-1)}.}
    \label{fig:sqrt-decomp-blocks}
\end{figure}

Já a rotina \texttt{update\_value(i, x)} é um pouco mais simples. Ao atualizamos o valor da posição $i$, temos simplesmente que atualizar o valor pré-calculado do bloco que o contém, e isso é o suficiente.

Note que a segunda operação tem um custo constante, dado que apenas atualizamos um único valor, porém a primeira operação requer uma análise mais cuidadosa. Para encontrar os valores das \emph{pontas}, $x$ e $z$, somos obrigados a realizar um \emph{loop} sob estes elementos, e como no pior caso podemos acabar percorrendo $b-1$ elementos, esta etapa tem custo $\Oh(b)$. Já para encontrar $y$, iteramos sob os blocos em si, portanto, no pior caso, gastamos $\Oh(d)$ para o seu cálculo. Com isso, temos que a consulta \texttt{find\_sum} tem um custo final $\Oh(\max(b, d))$.

Com o intuito de maximizarmos a eficiência desta função, queremos encontrar um tamanho de bloco $b$ ótimo que minimize o valor de $\max(b, d)$, isto é, que tornem $b$ e $d$ os mais próximos possível. Para isso, podemos fazer:

\begin{equation}
    b = d \Rightarrow
    b = \frac{n}{b} \Rightarrow
    b^2 = n \Rightarrow
    b = \pm \sqrt{n}
\end{equation}

Portanto, $\sqrt{n}$ é o tamanho ótimo para um bloco, o que implica que a nossa lista será dividida em $\sqrt{n}$ blocos, daí o nome da técnica. Finalmente, temos agora que a consulta \texttt{find\_sum} consome tempo $\Oh(\sqrt{n})$.

%% ------------------------------------------------------------------------- %%
\section{Rotinas extras para a versão incremental}
\label{sec:imsf-extras}

Antes de seguirmos adiante com a explicação versão do problema, temos que apresentar duas funções extras adicionadas na nossa solução para a versão incremental do problema. Em particular, ambas possuem o mesmo objetivo: possibilitar consultas acerca da floresta maximal de peso mínimo após a adição de um conjunto de arestas sem que tais modificações persistam na estrutura original. Em outras palavras, elas simulam o que poderia ser consultado caso fizéssemos estas adições de arestas em uma cópia da estrutura, porém, sem o custo adicional que tal cópia implica.

Essas rotinas são as \texttt{get\_msf\_after\_operations(edges[])} e \texttt{get\_msf\_weight\_after\_operations(edges[])}, que recebem uma lista de arestas e retornam, respectivamente, as arestas que fazem parte de uma floresta maximal de peso mínimo e seu peso caso as arestas da lista fornecida fossem adicionas ao grafo. Desta forma, a execução destes métodos consiste em três etapas: adição das arestas na estrutura; realização da consulta que estamos interessados; reversão da estrutura para o seu estado inicial.

Para a realização da primeira etapa, criamos o método \texttt{apply\_add\_edge\_operations}, que recebe uma lista de arestas, e realiza a adição delas na estrutura, de maneira muito similar ao que acontece na rotina \texttt{add\_edge}. Entretanto, este método retorna uma lista de pares \texttt{\{operação, aresta\}}, indicando quais operações foram realizadas na \emph{link-cut tree} --- \texttt{link} ou \texttt{cut} --- assim como as arestas envolvidas em cada uma delas. Como este método é muito semelhante à rotina \texttt{add\_edge}, não mostraremos seu pseudo-código.

Logo, após realizarmos as consultas que estamos interessados, precisamos reverter as operações realizadas na \emph{link-cut tree}. Para isso, criamos o método \texttt{apply\_rollback}, que recebe a lista criada pela rotina acima e desfaz as operações. Note que, para mantermos a consistência da \emph{link-cut tree} durante este processo, precisamos percorrer esta lista de trás para frente, revertendo uma operação de cada vez.

\begin{algorithm}[h!]
    \caption{Rotina Apply Rollback}\label{imsf-apply-rollback}
    \begin{algorithmic}[1]
        \Function{apply\_rollback}{\emph{operations\_list[]}}
        \State \emph{revert(operations\_list)}
        \ForEach{\emph{(operation, edge) in operations\_list}}
        \If{\emph{operation = link}}
        \State \emph{linkCutTree.cut(edge.u, edge.v)}
        \State \emph{current\_msf.erase(edge.id)}
        \State \emph{current\_msf\_weight -= edge.w}
        \Else
        \State \emph{linkCutTree.link(edge.u, edge.v, edge.w, edge.id)}
        \State \emph{current\_msf.append(edge.id)}
        \State \emph{current\_msf\_weight += edge.w}
        \EndIf
        \EndFor
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Finalmente, com estes métodos em mãos, podemos implementar as rotinas extras que estávamos interessados. Vamos mostrar somente o pseudo-código da rotina \texttt{get\_msf\_after\_operations}, dado que a única diferença entre as duas implementações seria a chamada na terceira linha.

\begin{algorithm}[h!]
    \caption{Rotina Get MSF After Operations}\label{imsf-msf-after}
    \begin{algorithmic}[1]
        \Function{get\_msf\_after\_operations}{\emph{edges[]}}
        \State \emph{rollback\_operations $\gets$ apply\_add\_edge\_operations(edges)}
        \State \emph{msf $\gets$ get\_msf()}
        \State \emph{apply\_rollback(rollback\_operations)}
        \State \Return \emph{msf}
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Além disso, podemos perceber que a complexidade destes métodos é proporcional à $\Oh(q \log m)$, onde $q$ é o número de arestas na lista \texttt{edges[]}.

%% ------------------------------------------------------------------------- %%
\section{Ideia}
\label{sec:rmsf-ideia}

% \todo{mostrar ideia, falar que a implimentaçao que vamos mostrar tem uma limitacao, por isso chamamos ela de semi retroativa}
% \todo{falar floresta geradora maximal de peso minima}
% \todo{mostrar implementação de 1 ou 2 métodos internos}

Agora, com todas as peças necessárias em mãos, podemos partir para a explicação da solução. Assim como no Capítulo \ref{cap:incremental-msf}, estamos interessados em resolver o \emph{problema da floresta geradora maximal de peso mínimo}, porém agora em sua versão semi-retroativa.

Em particular, queremos ser capazes de adicionar uma aresta ao grafo em certo estante de tempo, assim como realizar consultas acerca da floresta geradora maximal de peso mínimo em algum momento do presente ou do passado. Para isso, a estrutura deve conseguir dar suporte a seguinte interface:

\begin{itemize}
    \item \texttt{add\_edge(u, v, w, t)}: adiciona no grafo a aresta com pontas em $u$ e $v$ com peso $w$ no instante $t$;
    \item \texttt{get\_msf(t)}: retorna a lista com todas as arestas que compõem uma floresta maximal de peso mínimo do grafo no instante $t$;
    \item \texttt{get\_msf\_weight(t)}: retorna o custo de uma floresta maximal de peso mínimo do grafo no instante $t$.
\end{itemize}

A seguir, vamos apresentar duas soluções para este problema: a primeira delas é a versão original de Andrade Júnior e Duarte Seabra, que fornece os métodos acima com um custo de $\Oh(\sqrt m \log n)$ por operação --- onde $m$ é o número de operações realizadas até o instante atual e $n$ é o número de vértices do grafo, porém essa abordagem apresenta uma restrição em relação a quantidade de operações que podem ser realizadas na estrutura; já a segunda solução corresponde a uma melhoria da versão original, onde eliminamos a restrição acerca da quantidade de operações, oferecendo um custo amortizado de $\Oh(\sqrt m \log n)$ por operação.

%% ------------------------------------------------------------------------- %%
\subsection{Versão original}
\label{sec:rmsf-versao-ori}

Inicialmente, vamos pensar em como resolver este problema de uma maneira ingênua, isto é, sem usar as técnicas mais sofisticadas que vimos até agora. Para isso, podemos manter uma lista ordenada \texttt{edges\_by\_time}, onde cada posição corresponde a uma operação \texttt{add\_edge(u,v,w,t)}, com a aresta \texttt{(u,v,w)} sendo armazenada como valor e \texttt{t} sendo usado como chave de ordenação para a lista. Assim, podemos responder às consultas da seguinte maneira: separamos todas as arestas inseridas até o instante de tempo $t$ fornecido para a consulta e executamos, por exemplo, o algoritmo de Kruskal para determinar a floresta geradora maximal de custo mínimo. Dessa maneira, o consumo de tempo da rotina \texttt{add\_edge} é $\Oh (log m)$ --- sendo $m$ o número de inserções realizadas, e o consumo de tempo das consultas \texttt{get\_msf} e \texttt{get\_msf\_weight} é de $\Oh(m \log m)$, pois no pior caso executamos o algoritmo de Kruskal para todas as arestas na lista.

Como podemos perceber, a solução acima gasta muito tempo construindo a resposta do zero para cada uma das consultas. Para melhorar isso, Andrade Júnior e Duarte Seabra sugerem uma maneira de acelerar esta etapa de construção de resposta, mas comprometendo um pouco o custo da rotina de inserção de novas arestas, através do uso da técnica de \emph{square root decomposition}.

Para procedermos com a explicação, precisamos assumir duas coisas: que $m$ é um inteiro conhecido de antemão, representando o número total de arestas a serem inseridas no grafo; e que o instante de tempo fornecido a toda operação esteja no intervalo $[1,m]$. Esses dois detalhes representam uma grande restrição para a versão original, e buscamos eliminá-los na versão melhorada da solução. Além disso, sem perda de generalidade, vamos assumir que $m$ é um quadrado perfeito.

Primeiramente, utilizando a ideia de \emph{square root decomposition}, vamos dividir a lista \texttt{edges\_by\_time} em $\sqrt m$ blocos. Além disso, definimos os \emph{checkpoints} $c_1, c_2, \dots, c_{\sqrt m}$, que correspondem aos instantes de tempo no fim de cada bloco, assim temos que $c_i$ corresponde ao instante de tempo $i \sqrt m$. Em seguida, atribuímos uma floresta geradora mínima incremental $t_i$ a cada \emph{checkpoint}, onde $t_i$ é incrementada com todas as arestas inseridas em um instante de tempo menor ou igual a $c_i$.

Em outras palavras, podemos descrever esta construção da seguinte maneira: dividimos a lista de inserções em $\sqrt m$ blocos de tamanho $\sqrt m$, onde cada bloco possui uma estrutura para resolver o problema da floresta geradora mínima incremental. Dessa forma, fazemos com que a estrutura em cada bloco possua todas as arestas inseridas desde o instante de tempo $1$ até o instante de tempo máximo contido naquele bloco

\begin{figure}
    \centering
    \begin{equation*}
        \overbracket{
            \overbracket{
                \overbracket{
                    \overbracket{
                        \overbracket{
                            \bolinha{\,0\,}
                        }^{t_0}
                        \bolinha{\,1\,}
                        \bolinha{\,2\,}
                        \bolinha{\,3\,}
                        \bolinha{\,4\,}
                    }^{t_1}
                    \bolinha{\,5\,}
                    \bolinha{\,6\,}
                    \bolinha{\,7\,}
                    \bolinha{\,8\,}
                }^{t_2}
                \bolinha{\,9\,}
                \bolinha{10}
                \bolinha{11}
                \bolinha{12}
            }^{t_3}
            \bolinha{13}
            \bolinha{14}
            \bolinha{15}
            \bolinha{16}
        }^{t_4}
    \end{equation*}
    \caption{Representação da lista \texttt{edges\_by\_time} com $m$ igual a $16$. Neste caso, cada bloco tem tamanho $4$ e os instantes $0,4,8,12$ e $16$ são $c_0, c_1, c_2, c_3$ e $c_4$, respectivamente. Assim, por exemplo, a estrutura $t_3$ contém todas as arestas adicionadas desde o instante $1$ até o instante $12$.}
    \label{fig:sqrt-decomp-blocks-m16}
\end{figure}

A partir dessa construção, podemos responder uma consulta acerca do estado da floresta geradora maximal de peso mínimo no instante de tempo $t$ utilizando a seguinte abordagem:

\begin{itemize}
    \item para começar, precisamos encontrar o último bloco da decomposição que não possui a aresta adicionada no instante de tempo $t$, ou o bloco que a possui em seu extremo. Mais formalmente, isso corresponde a encontrarmos o maior $i$ tal que $c_i \leq t$ vale;
    \item em seguida, vamos \emph{aumentar} este bloco até que ele possua todas as operações de inserção até o instante $t$, isto é, com a estrutura $t_i$ em mãos, incrementamos ela com todas as arestas adicionadas entre os instantes $c_i + 1$ e $t$;
    \item finalmente, basta retornar a consulta de interesse, isto é, as arestas que compõem a floresta geradora ou o seu respectivo peso.
\end{itemize}

Vale notar que, caso a consulta aconteça no primeiro bloco, não existe uma estrutura inicial a qual podemos utilizar para incrementar a resposta final. Por isso, vamos definir o \emph{checkpoint} $c_0 = 0$ e sua respectiva estrutura $t_0$, uma floresta geradora mínima incremental de um grafo vazio.

Agora, para executamos uma rotina \texttt{add\_edge(u,v,w,t)} fazemos o seguinte:

\begin{itemize}
    \item inicialmente, encontramos o primeiro bloco em que a aresta adicionada no instante $t$ deve ser passada para a estrutura incremental, ou seja, o menor $i$ tal que $t \leq c_i$ é verdade;
    \item por último, basta adicionarmos esta aresta nas estruturas de cada bloco daqui para frente, o que se traduz em realizarmos uma operação de \texttt{add\_edge(u,v,w)} em todas as $t_j$, com $j \in [i, \sqrt m]$.
\end{itemize}

Finalmente, podemos analisar a complexidade desta solução, onde $m$ é o número de operações realizadas e $n$ é o número de vértices do grafo.

Para as consultas, podemos perceber que o primeiro passo tem custo $\Oh(\sqrt m)$, dado que temos que percorrer todos os blocos até encontrarmos o $i$ de interesse. Já a segundo passo implica um custo amortizado de $\Oh(\sqrt m \log n)$, dado que, no pior caso, teremos que adicionar quase todas as arestas de um bloco na estrutura incremental. Assim, a consulta \texttt{get\_msf} fica com um custo amortizado de $\Oh(m + \sqrt m \log n) = \Oh(m)$ e a consulta \texttt{get\_msf\_weight} fica com custo amortizado de $\Oh(1 + \sqrt m \log n) = \Oh(\sqrt m \log n)$.

Além disso, na rotina \texttt{add\_edge}, podemos ter que adicionar a aresta na estrutura incremental de quase todos os blocos da decomposição, com isso, seu custo amortizado também será de $\Oh(\sqrt m \log n)$.

%% ------------------------------------------------------------------------- %%
\subsection{Versão melhorada}
\label{sec:rmsf-versao-mel}

Como podemos ver acima, a versão original de Andrade Júnior e Duarte Seabra oferece uma solução para o problema que estamos interessados em resolver, porém, as restrições que a acompanham acabam se tornando um grande inconveniente. Logo, ao refletirmos sobre maneiras de melhorar a ideia apresentada, rapidamente notamos que a construção inicial da decomposição acaba se tornando um limitante para a estrutura.

Em particular, a construção realizada na versão original se baseia no artigo proponente da ideia de estruturas de dados retroativas, de Demaine, Iacono et al., que mostra uma receita para transformar estruturas parcialmente retroativas em estruturas totalmente retroativas --- traduzindo para o nosso caso, uma maneira para transformar a floresta geradora mínima incremental em uma retroativa. Entretanto, na abordagem sugerida pelo artigo, são diversas reconstruções da decomposição, conforme novas aresta vão sendo adicionadas. Mais especificamente, os autores sugerem uma reconstrução a cada $\frac{\sqrt m}{2}$ operações, de modo a garantir que nenhum bloco tenha tamanho maior que $\frac{3\sqrt m}{2}$.

Além disso, assumindo que a reconstrução possui um custo de $\Oh(m \log n)$, podemos distribuir este gasto de maneira amortizada em cada operação, fazendo com que o custo amortizado de cada uma continue sendo $\Oh(\sqrt m \log n)$. Todavia, para que a reconstrução tenha este custo, é necessário que estrutura parcialmente retroativa tenha uma versão persistente, de modo a  podermos utilizar uma única cópia para representar $t_0, t_1, \dots, t_{\sqrt m}$. Por sua vez, uma versão persistente da floresta geradora mínima incremental requer a implementação de uma \emph{link-cut tree} persistente, como a apresentada por \citet{10.1007/978-3-540-69903-3_16}. Porém, essa implementação é bastante sofisticada, e seu estudo fugiria do escopo deste trabalho.

Logo, estaremos interessados em resolver este problema utilizando uma versão não persistente da floresta geradora mínima incremental, criando uma cópia da estrutura para cada $t_i$. Desse modo, durante uma reconstrução, as operações do último bloco serão inseridas em $t_{\sqrt m}$, as operações do penúltimo bloco serão inseridas em $t_{\sqrt m - 1}$ e $t_{\sqrt m}$, e assim por diante. Portanto, podemos calcular o custo dessa reconstrução da seguinte maneira:

\begin{equation}
    \sum_{i=1}^{\sqrt m} (i \sqrt m \log n) =
    \frac{m \log n \: (\sqrt m + 1)}{2} \Rightarrow
    \Oh(m \log n \sqrt m).
\end{equation}

Ou seja, com o custo da reconstrução apresentado acima, cada operação teria agora um custo amortizado de $\Oh(m \log n)$, o que esta longe do ideal. Neste ponto, nossa abordagem para solucionar o problema fica bastante criativa, com a apresentação de uma maneira totalmente nova de realizar tal tarefa.

% apresentar nossa ideia, de reaproveitar a estrutura e reconstruir a cada quadrado perfeito

%% ------------------------------------------------------------------------- %%
\subsection{Complexidade}
\label{sec:rmsf-complexidade}



\todo{falar da alternativa usada no paper do andre para contornar o problema da complexidade}
\todo{falar que poderiamos adaptar essa solucao usando link-cut trees persistentes, citar paper que a Cris mandou}
\todo{falar da complexidade da nossa variante da solucao proposta por Demaine}

% corolário: são realizadas 2sqrt m operações entre 2 quadrados perfeitos

% teorema: cada t_i eh deslocada no máximo 4sqrt posições a cada reconstrução (provinha no email)

% deduzir complexidade através das provas


%% ------------------------------------------------------------------------- %%
\section{Rotina Build Decomposition}
\label{sec:rmsf-build-decomposition}



%% ------------------------------------------------------------------------- %%
\section{Consultas Get MSF e Get MST Weight}
\label{sec:rmsf-get-msf}



%% ------------------------------------------------------------------------- %%
\section{Rotina Add Edge}
\label{sec:rmsf-add-edge}

